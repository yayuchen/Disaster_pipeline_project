{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba411ecc",
   "metadata": {},
   "source": [
    "# ML pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948bac7e",
   "metadata": {},
   "source": [
    "## Procedures:\n",
    "\n",
    "1. [**Loading from database**](#1)\n",
    "2. [**Normalization, Tokenization, remove stop words and Lemmatization**](#2)\n",
    "3. [**Find the best performance classifier**](#3)\n",
    "4. [**Modifying hyper parameters**](#4)\n",
    "5. [**Tuning hyper parameters by GridSearchCV**](#5)\n",
    "6. [**Statistical report**](#6)\n",
    "7. [**Saving model as pickle file**](#7)\n",
    "8. [**Testing**](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8f131",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be40b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\EllenChen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\EllenChen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\EllenChen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid related</th>\n",
       "      <th>medical help</th>\n",
       "      <th>medical products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid centers</th>\n",
       "      <th>other infrastructure</th>\n",
       "      <th>weather related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other weather</th>\n",
       "      <th>direct report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre related request  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct       1       0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct       1       0   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct       1       0   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct       1       1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct       1       0   \n",
       "\n",
       "  offer aid related medical help medical products  ... aid centers  \\\n",
       "0     0           0            0                0  ...           0   \n",
       "1     0           1            0                0  ...           0   \n",
       "2     0           0            0                0  ...           0   \n",
       "3     0           1            0                1  ...           0   \n",
       "4     0           0            0                0  ...           0   \n",
       "\n",
       "  other infrastructure weather related floods storm fire earthquake cold  \\\n",
       "0                    0               0      0     0    0          0    0   \n",
       "1                    0               1      0     1    0          0    0   \n",
       "2                    0               0      0     0    0          0    0   \n",
       "3                    0               0      0     0    0          0    0   \n",
       "4                    0               0      0     0    0          0    0   \n",
       "\n",
       "  other weather direct report  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# load from database table\n",
    "engine = create_engine('sqlite:///../data/Disaster_database.db')\n",
    "df = pd.read_sql_table('overall', con = engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f143284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        26180\n",
       "message                   26177\n",
       "original                   9630\n",
       "genre                         3\n",
       "related                       3\n",
       "request                       2\n",
       "offer                         2\n",
       "aid related                   2\n",
       "medical help                  2\n",
       "medical products              2\n",
       "search and rescue             2\n",
       "security                      2\n",
       "military                      2\n",
       "child alone                   1\n",
       "water                         2\n",
       "food                          2\n",
       "shelter                       2\n",
       "clothing                      2\n",
       "money                         2\n",
       "missing people                2\n",
       "refugees                      2\n",
       "death                         2\n",
       "other aid                     2\n",
       "infrastructure related        2\n",
       "transport                     2\n",
       "buildings                     2\n",
       "electricity                   2\n",
       "tools                         2\n",
       "hospitals                     2\n",
       "shops                         2\n",
       "aid centers                   2\n",
       "other infrastructure          2\n",
       "weather related               2\n",
       "floods                        2\n",
       "storm                         2\n",
       "fire                          2\n",
       "earthquake                    2\n",
       "cold                          2\n",
       "other weather                 2\n",
       "direct report                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check values unique numbers\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717ea095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19906\n",
       "0     6122\n",
       "2      188\n",
       "Name: related, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check value number of related\n",
    "df.related.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c988b182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid related</th>\n",
       "      <th>medical help</th>\n",
       "      <th>medical products</th>\n",
       "      <th>search and rescue</th>\n",
       "      <th>...</th>\n",
       "      <th>aid centers</th>\n",
       "      <th>other infrastructure</th>\n",
       "      <th>weather related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other weather</th>\n",
       "      <th>direct report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26216</td>\n",
       "      <td>10170</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>...</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "      <td>26216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26177</td>\n",
       "      <td>9630</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>Nap fe ou konnen ke apati de jodi a sevis SMS ...</td>\n",
       "      <td>news</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>13054</td>\n",
       "      <td>20094</td>\n",
       "      <td>21742</td>\n",
       "      <td>26098</td>\n",
       "      <td>15356</td>\n",
       "      <td>24132</td>\n",
       "      <td>24903</td>\n",
       "      <td>25492</td>\n",
       "      <td>...</td>\n",
       "      <td>25907</td>\n",
       "      <td>25065</td>\n",
       "      <td>18919</td>\n",
       "      <td>24061</td>\n",
       "      <td>23773</td>\n",
       "      <td>25934</td>\n",
       "      <td>23761</td>\n",
       "      <td>25686</td>\n",
       "      <td>24840</td>\n",
       "      <td>21141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       message                                           original  genre  \\\n",
       "count    26216                                              10170  26216   \n",
       "unique   26177                                               9630      3   \n",
       "top     #NAME?  Nap fe ou konnen ke apati de jodi a sevis SMS ...   news   \n",
       "freq         4                                                 20  13054   \n",
       "\n",
       "       related request  offer aid related medical help medical products  \\\n",
       "count    26216   26216  26216       26216        26216            26216   \n",
       "unique       2       2      2           2            2                2   \n",
       "top          1       0      0           0            0                0   \n",
       "freq     20094   21742  26098       15356        24132            24903   \n",
       "\n",
       "       search and rescue  ... aid centers other infrastructure  \\\n",
       "count              26216  ...       26216                26216   \n",
       "unique                 2  ...           2                    2   \n",
       "top                    0  ...           0                    0   \n",
       "freq               25492  ...       25907                25065   \n",
       "\n",
       "       weather related floods  storm   fire earthquake   cold other weather  \\\n",
       "count            26216  26216  26216  26216      26216  26216         26216   \n",
       "unique               2      2      2      2          2      2             2   \n",
       "top                  0      0      0      0          0      0             0   \n",
       "freq             18919  24061  23773  25934      23761  25686         24840   \n",
       "\n",
       "       direct report  \n",
       "count          26216  \n",
       "unique             2  \n",
       "top                0  \n",
       "freq           21141  \n",
       "\n",
       "[4 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace 2 as 1\n",
    "df.related = df.related.map(lambda x: '1' if x == '2' else x)\n",
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06aac78",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4837502",
   "metadata": {},
   "source": [
    "### Procedures:\n",
    "1. Detecting any url like text, replace as urlplaceholder\n",
    "2. Replacing punctuation with empty space\n",
    "3. Tokenizing lower case text\n",
    "4. Removing stop words\n",
    "5. Lemmatizing text as new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63e58226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace url address as urlplaceholder\n",
    "# tokenize and lemmatize text\n",
    "\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "def tokenize(text):\n",
    "    # find url text and replace as urlplace text\n",
    "    detect_url = re.findall(url_regex, text)\n",
    "    for url in detect_url:\n",
    "        text = text.replace(url, 'urlplaceholder')\n",
    "        \n",
    "    # norlamized and tokenized\n",
    "    texts = word_tokenize(re.sub('[^a-zA-Z0-9]', ' ', text.lower()))\n",
    "    # remove stopwords\n",
    "    words = [w for w in texts if w not in stopwords.words('english')]\n",
    "    # tokenize and lemmatizer text\n",
    "    clean_tokens = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dc3d48",
   "metadata": {},
   "source": [
    "### Define independent and targt variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067d8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define and split independent and target variable\n",
    "X = df.message.values\n",
    "Y = df[df.columns[4:]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60857e49",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## Trying to find the best performance classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daca096",
   "metadata": {},
   "source": [
    "Using **Pipeline** for automatically operating each steps, due to this case has multilabels, thus, **MultiOutputClassifier** can help to avoid error. Setting a new variable called models for different classifiers, combining with **for loop** to find out the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5af855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n",
      "0.9484708235852575\n",
      "DecisionTreeClassifier(random_state=42)\n",
      "0.9322381582070322\n",
      "KNeighborsClassifier()\n",
      "0.928249923710711\n"
     ]
    }
   ],
   "source": [
    "# use for loop to check which classifier has the highest accuracy\n",
    "# use multioutputclassifier for multiclass - multioutput case\n",
    "\n",
    "RC = RandomForestClassifier(random_state=42)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "KNC = KNeighborsClassifier()\n",
    "\n",
    "models = [RC, DTC, KNC]\n",
    "\n",
    "for model in models:\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(model))])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy = (y_test == y_pred).mean()\n",
    "    print(model)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0812c5",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## Modifying the hyper parameters for find better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb6fb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vect', CountVectorizer(tokenizer=<function tokenize at 0x000001D969B16AF0>)), ('tfidf', TfidfTransformer()), ('clf', MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=200,\n",
      "                                                       random_state=42)))], 'verbose': False, 'vect': CountVectorizer(tokenizer=<function tokenize at 0x000001D969B16AF0>), 'tfidf': TfidfTransformer(), 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(n_estimators=200,\n",
      "                                                       random_state=42)), 'vect__analyzer': 'word', 'vect__binary': False, 'vect__decode_error': 'strict', 'vect__dtype': <class 'numpy.int64'>, 'vect__encoding': 'utf-8', 'vect__input': 'content', 'vect__lowercase': True, 'vect__max_df': 1.0, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 1), 'vect__preprocessor': None, 'vect__stop_words': None, 'vect__strip_accents': None, 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vect__tokenizer': <function tokenize at 0x000001D969B16AF0>, 'vect__vocabulary': None, 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': True, 'clf__estimator__bootstrap': True, 'clf__estimator__ccp_alpha': 0.0, 'clf__estimator__class_weight': None, 'clf__estimator__criterion': 'gini', 'clf__estimator__max_depth': None, 'clf__estimator__max_features': 'auto', 'clf__estimator__max_leaf_nodes': None, 'clf__estimator__max_samples': None, 'clf__estimator__min_impurity_decrease': 0.0, 'clf__estimator__min_impurity_split': None, 'clf__estimator__min_samples_leaf': 1, 'clf__estimator__min_samples_split': 2, 'clf__estimator__min_weight_fraction_leaf': 0.0, 'clf__estimator__n_estimators': 200, 'clf__estimator__n_jobs': None, 'clf__estimator__oob_score': False, 'clf__estimator__random_state': 42, 'clf__estimator__verbose': 0, 'clf__estimator__warm_start': False, 'clf__estimator': RandomForestClassifier(n_estimators=200, random_state=42), 'clf__n_jobs': None}\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42,\n",
    "                                                             n_estimators=200)))])\n",
    "\n",
    "# inspect the entire hyper parameters of model\n",
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66260558",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## Tuning hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73864fe",
   "metadata": {},
   "source": [
    "Using **GridSearchCV** and self setting parameters in dict type, calling **best_params_** method to check the best parameters after train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fca75c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__estimator__max_samples': None, 'clf__estimator__n_estimators': 200, 'vect__max_features': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# custom hyper parameter in dict format\n",
    "parameters = {'vect__max_features': [None, 5, 10],\n",
    "              'clf__estimator__n_estimators': [100, 200],\n",
    "              'clf__estimator__max_samples': [None, 10, 20]}\n",
    "\n",
    "cv = GridSearchCV(model, parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# fine the best performance hyper parameters\n",
    "best_params = cv.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfb3c7",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## Statistical report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc3424",
   "metadata": {},
   "source": [
    "- Using **confusion matrix** for matching statistical numbers of each label.\n",
    "- Using **classification report** for precision, recall and f1 score of each label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e473c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdcf67a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Name: RELATED\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[ 598  929]\n",
      " [ 241 4786]] \n",
      "\n",
      "RELATED accuracy: 0.8214830637778456 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.39      0.51      1527\n",
      "           1       0.84      0.95      0.89      5027\n",
      "\n",
      "    accuracy                           0.82      6554\n",
      "   macro avg       0.78      0.67      0.70      6554\n",
      "weighted avg       0.81      0.82      0.80      6554\n",
      " \n",
      "\n",
      "Labels Name: REQUEST\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5291  119]\n",
      " [ 586  558]] \n",
      "\n",
      "REQUEST accuracy: 0.8924321025328044 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5410\n",
      "           1       0.82      0.49      0.61      1144\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.86      0.73      0.78      6554\n",
      "weighted avg       0.89      0.89      0.88      6554\n",
      " \n",
      "\n",
      "Labels Name: OFFER\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6525    0]\n",
      " [  29    0]] \n",
      "\n",
      "OFFER accuracy: 0.995575221238938 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6525\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      " \n",
      "\n",
      "Labels Name: AID RELATED\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[3232  605]\n",
      " [ 798 1919]] \n",
      "\n",
      "AID RELATED accuracy: 0.7859322551113823 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      3837\n",
      "           1       0.76      0.71      0.73      2717\n",
      "\n",
      "    accuracy                           0.79      6554\n",
      "   macro avg       0.78      0.77      0.78      6554\n",
      "weighted avg       0.78      0.79      0.78      6554\n",
      " \n",
      "\n",
      "Labels Name: MEDICAL HELP\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6003   18]\n",
      " [ 502   31]] \n",
      "\n",
      "MEDICAL HELP accuracy: 0.9206591394568202 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      6021\n",
      "           1       0.63      0.06      0.11       533\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.78      0.53      0.53      6554\n",
      "weighted avg       0.90      0.92      0.89      6554\n",
      " \n",
      "\n",
      "Labels Name: MEDICAL PRODUCTS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6200    6]\n",
      " [ 310   38]] \n",
      "\n",
      "MEDICAL PRODUCTS accuracy: 0.9517851693622216 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6206\n",
      "           1       0.86      0.11      0.19       348\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.91      0.55      0.58      6554\n",
      "weighted avg       0.95      0.95      0.93      6554\n",
      " \n",
      "\n",
      "Labels Name: SEARCH AND RESCUE\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6370    0]\n",
      " [ 175    9]] \n",
      "\n",
      "SEARCH AND RESCUE accuracy: 0.9732987488556607 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6370\n",
      "           1       1.00      0.05      0.09       184\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.99      0.52      0.54      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      " \n",
      "\n",
      "Labels Name: SECURITY\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6443    1]\n",
      " [ 110    0]] \n",
      "\n",
      "SECURITY accuracy: 0.9830637778455905 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6444\n",
      "           1       0.00      0.00      0.00       110\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      " \n",
      "\n",
      "Labels Name: MILITARY\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6338    4]\n",
      " [ 191   21]] \n",
      "\n",
      "MILITARY accuracy: 0.9702471772963076 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6342\n",
      "           1       0.84      0.10      0.18       212\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.91      0.55      0.58      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      " \n",
      "\n",
      "Labels Name: CHILD ALONE\n",
      "Labels: ['0']\n",
      "Confusion matrix of each label:\n",
      " [[6554]] \n",
      "\n",
      "CHILD ALONE accuracy: 1.0 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      " \n",
      "\n",
      "Labels Name: WATER\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6130   13]\n",
      " [ 259  152]] \n",
      "\n",
      "WATER accuracy: 0.9584986267927983 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6143\n",
      "           1       0.92      0.37      0.53       411\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.94      0.68      0.75      6554\n",
      "weighted avg       0.96      0.96      0.95      6554\n",
      " \n",
      "\n",
      "Labels Name: FOOD\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5755   65]\n",
      " [ 275  459]] \n",
      "\n",
      "FOOD accuracy: 0.9481232834909978 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5820\n",
      "           1       0.88      0.63      0.73       734\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.92      0.81      0.85      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      " \n",
      "\n",
      "Labels Name: SHELTER\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5964   40]\n",
      " [ 335  215]] \n",
      "\n",
      "SHELTER accuracy: 0.94278303326213 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      6004\n",
      "           1       0.84      0.39      0.53       550\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.89      0.69      0.75      6554\n",
      "weighted avg       0.94      0.94      0.93      6554\n",
      " \n",
      "\n",
      "Labels Name: CLOTHING\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6451    1]\n",
      " [  91   11]] \n",
      "\n",
      "CLOTHING accuracy: 0.9859627708269759 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6452\n",
      "           1       0.92      0.11      0.19       102\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.95      0.55      0.59      6554\n",
      "weighted avg       0.99      0.99      0.98      6554\n",
      " \n",
      "\n",
      "Labels Name: MONEY\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6404    1]\n",
      " [ 146    3]] \n",
      "\n",
      "MONEY accuracy: 0.977570949038755 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6405\n",
      "           1       0.75      0.02      0.04       149\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.86      0.51      0.51      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      " \n",
      "\n",
      "Labels Name: MISSING PEOPLE\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6478    0]\n",
      " [  76    0]] \n",
      "\n",
      "MISSING PEOPLE accuracy: 0.9884040280744584 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6478\n",
      "           1       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "\n",
      "Labels Name: REFUGEES\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6351    1]\n",
      " [ 198    4]] \n",
      "\n",
      "REFUGEES accuracy: 0.969636862984437 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6352\n",
      "           1       0.80      0.02      0.04       202\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.88      0.51      0.51      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      " \n",
      "\n",
      "Labels Name: DEATH\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6239   14]\n",
      " [ 256   45]] \n",
      "\n",
      "DEATH accuracy: 0.9588037839487336 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6253\n",
      "           1       0.76      0.15      0.25       301\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.86      0.57      0.61      6554\n",
      "weighted avg       0.95      0.96      0.95      6554\n",
      " \n",
      "\n",
      "Labels Name: OTHER AID\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5660   17]\n",
      " [ 848   29]] \n",
      "\n",
      "OTHER AID accuracy: 0.8680195300579798 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5677\n",
      "           1       0.63      0.03      0.06       877\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.75      0.52      0.50      6554\n",
      "weighted avg       0.84      0.87      0.81      6554\n",
      " \n",
      "\n",
      "Labels Name: INFRASTRUCTURE RELATED\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6133    4]\n",
      " [ 417    0]] \n",
      "\n",
      "INFRASTRUCTURE RELATED accuracy: 0.935764418675618 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6137\n",
      "           1       0.00      0.00      0.00       417\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.47      0.50      0.48      6554\n",
      "weighted avg       0.88      0.94      0.91      6554\n",
      " \n",
      "\n",
      "Labels Name: TRANSPORT\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6239   13]\n",
      " [ 274   28]] \n",
      "\n",
      "TRANSPORT accuracy: 0.9562099481232835 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6252\n",
      "           1       0.68      0.09      0.16       302\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.82      0.55      0.57      6554\n",
      "weighted avg       0.95      0.96      0.94      6554\n",
      " \n",
      "\n",
      "Labels Name: BUILDINGS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6223    5]\n",
      " [ 290   36]] \n",
      "\n",
      "BUILDINGS accuracy: 0.9549893194995422 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6228\n",
      "           1       0.88      0.11      0.20       326\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.92      0.55      0.59      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      " \n",
      "\n",
      "Labels Name: ELECTRICITY\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6426    1]\n",
      " [ 120    7]] \n",
      "\n",
      "ELECTRICITY accuracy: 0.981537992065914 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6427\n",
      "           1       0.88      0.06      0.10       127\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.93      0.53      0.55      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      " \n",
      "\n",
      "Labels Name: TOOLS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6512    0]\n",
      " [  42    0]] \n",
      "\n",
      "TOOLS accuracy: 0.9935916997253585 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6512\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      " \n",
      "\n",
      "Labels Name: HOSPITALS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6481    0]\n",
      " [  73    0]] \n",
      "\n",
      "HOSPITALS accuracy: 0.9888617638083613 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6481\n",
      "           1       0.00      0.00      0.00        73\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      " \n",
      "\n",
      "Labels Name: SHOPS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6531    0]\n",
      " [  23    0]] \n",
      "\n",
      "SHOPS accuracy: 0.996490692706744 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6531\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      " \n",
      "\n",
      "Labels Name: AID CENTERS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6490    0]\n",
      " [  64    0]] \n",
      "\n",
      "AID CENTERS accuracy: 0.9902349710100702 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6490\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.99      6554\n",
      " \n",
      "\n",
      "Labels Name: OTHER INFRASTRUCTURE\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6268    3]\n",
      " [ 283    0]] \n",
      "\n",
      "OTHER INFRASTRUCTURE accuracy: 0.9563625267012511 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\EllenChen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6271\n",
      "           1       0.00      0.00      0.00       283\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.92      0.96      0.94      6554\n",
      " \n",
      "\n",
      "Labels Name: WEATHER RELATED\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[4573  210]\n",
      " [ 523 1248]] \n",
      "\n",
      "WEATHER RELATED accuracy: 0.8881599023497101 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      4783\n",
      "           1       0.86      0.70      0.77      1771\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.88      0.83      0.85      6554\n",
      "weighted avg       0.89      0.89      0.88      6554\n",
      " \n",
      "\n",
      "Labels Name: FLOODS\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6022   31]\n",
      " [ 256  245]] \n",
      "\n",
      "FLOODS accuracy: 0.9562099481232835 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      6053\n",
      "           1       0.89      0.49      0.63       501\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.92      0.74      0.80      6554\n",
      "weighted avg       0.95      0.96      0.95      6554\n",
      " \n",
      "\n",
      "Labels Name: STORM\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5888   90]\n",
      " [ 245  331]] \n",
      "\n",
      "STORM accuracy: 0.9488861763808362 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5978\n",
      "           1       0.79      0.57      0.66       576\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.87      0.78      0.82      6554\n",
      "weighted avg       0.94      0.95      0.95      6554\n",
      " \n",
      "\n",
      "Labels Name: FIRE\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6472    0]\n",
      " [  81    1]] \n",
      "\n",
      "FIRE accuracy: 0.98764113518462 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6472\n",
      "           1       1.00      0.01      0.02        82\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.99      0.51      0.51      6554\n",
      "weighted avg       0.99      0.99      0.98      6554\n",
      " \n",
      "\n",
      "Labels Name: EARTHQUAKE\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5908   50]\n",
      " [ 113  483]] \n",
      "\n",
      "EARTHQUAKE accuracy: 0.9751296917912725 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      5958\n",
      "           1       0.91      0.81      0.86       596\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.94      0.90      0.92      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      " \n",
      "\n",
      "Labels Name: COLD\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6423    3]\n",
      " [ 116   12]] \n",
      "\n",
      "COLD accuracy: 0.9818431492218492 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6426\n",
      "           1       0.80      0.09      0.17       128\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.89      0.55      0.58      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      " \n",
      "\n",
      "Labels Name: OTHER WEATHER\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[6210    8]\n",
      " [ 327    9]] \n",
      "\n",
      "OTHER WEATHER accuracy: 0.9488861763808362 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6218\n",
      "           1       0.53      0.03      0.05       336\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.74      0.51      0.51      6554\n",
      "weighted avg       0.93      0.95      0.93      6554\n",
      " \n",
      "\n",
      "Labels Name: DIRECT REPORT\n",
      "Labels: ['0' '1']\n",
      "Confusion matrix of each label:\n",
      " [[5160  132]\n",
      " [ 800  462]] \n",
      "\n",
      "DIRECT REPORT accuracy: 0.8577967653341471 \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      5292\n",
      "           1       0.78      0.37      0.50      1262\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.82      0.67      0.71      6554\n",
      "weighted avg       0.85      0.86      0.84      6554\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# extract y_test and y_pred by 35 different labels and append to new list variables\n",
    "true = []\n",
    "pred = []\n",
    "\n",
    "for i in range(36):\n",
    "    true.append(y_test[:,i])\n",
    "    pred.append(y_pred[:,i])\n",
    "\n",
    "col_name = df.columns[4:].values\n",
    "\n",
    "# output each label's confusion matrix and classification report \n",
    "for t, p, col in zip(true, pred, col_name):\n",
    "    labels = np.unique(t)\n",
    "    confusion_mat = confusion_matrix(t, p, labels= labels)\n",
    "    label_accuracy = (t == p).mean()\n",
    "\n",
    "    print('Labels Name:', col.upper())\n",
    "    print('Labels:', labels)\n",
    "    print('Confusion matrix of each label:\\n', confusion_mat, '\\n')\n",
    "    print('{} accuracy:'.format(col.upper()), label_accuracy, '\\n')\n",
    "    print('Classification Report: \\n', classification_report(t, p), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749e3981",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc434893",
   "metadata": {},
   "source": [
    "Storing trained and optimized model as a new **pickle file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec626deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9497465500288204\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save model \n",
    "pickle.dump(model, open('disaster_model.pkl', 'wb'))\n",
    "\n",
    "# load model\n",
    "loaded_model = pickle.load(open('disaster_model.pkl', 'rb'))\n",
    "\n",
    "# check accuracy\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = (y_test == y_pred).mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46fde3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9497465500288204\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open('disaster_model.pkl', 'rb'))\n",
    "\n",
    "# check accuracy\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = (y_test == y_pred).mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71afacb",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "## Test pipeline output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1243165d",
   "metadata": {},
   "source": [
    "Loading saved **pickle file** as a new model variable and test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59594bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9497465500288204\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open('disaster_model.pkl', 'rb'))\n",
    "\n",
    "# check accuracy\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "accuracy = (y_test == y_pred).mean()\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
